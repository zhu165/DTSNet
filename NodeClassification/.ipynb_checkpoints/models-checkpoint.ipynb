{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2b5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GATConv, GCNConv, ChebConv\n",
    "from torch_geometric.nn import MessagePassing, APPNP\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "from scipy.special import comb\n",
    "from Bernpro import Bern_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4809aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPR_prop(MessagePassing):\n",
    "    '''\n",
    "    propagation class for GPR_GNN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, K, alpha, Init, Gamma=None, bias=True, **kwargs):\n",
    "        super(GPR_prop, self).__init__(aggr='add', **kwargs)\n",
    "        self.K = K\n",
    "        self.Init = Init\n",
    "        self.alpha = alpha\n",
    "\n",
    "        assert Init in ['SGC', 'PPR', 'NPPR', 'Random', 'WS']\n",
    "        if Init == 'SGC':\n",
    "            # SGC-like\n",
    "            TEMP = 0.0*np.ones(K+1)\n",
    "            TEMP[-1] = 1.0\n",
    "        elif Init == 'PPR':\n",
    "            # PPR-like\n",
    "            TEMP = alpha*(1-alpha)**np.arange(K+1)\n",
    "            TEMP[-1] = (1-alpha)**K\n",
    "        elif Init == 'NPPR':\n",
    "            # Negative PPR\n",
    "            TEMP = (alpha)**np.arange(K+1)\n",
    "            TEMP = TEMP/np.sum(np.abs(TEMP))\n",
    "        elif Init == 'Random':\n",
    "            # Random\n",
    "            bound = np.sqrt(3/(K+1))\n",
    "            TEMP = np.random.uniform(-bound, bound, K+1)\n",
    "            TEMP = TEMP/np.sum(np.abs(TEMP))\n",
    "        elif Init == 'WS':\n",
    "            # Specify Gamma\n",
    "            TEMP = Gamma\n",
    "\n",
    "        self.temp = Parameter(torch.tensor(TEMP))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.zeros_(self.temp)\n",
    "        for k in range(self.K+1):\n",
    "            self.temp.data[k] = self.alpha*(1-self.alpha)**k\n",
    "        self.temp.data[-1] = (1-self.alpha)**self.K\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        edge_index, norm = gcn_norm(\n",
    "            edge_index, edge_weight, num_nodes=x.size(0), dtype=x.dtype)\n",
    "\n",
    "        hidden = x*(self.temp[0])\n",
    "        for k in range(self.K):\n",
    "            x = self.propagate(edge_index, x=x, norm=norm)\n",
    "            gamma = self.temp[k+1]\n",
    "            hidden = hidden + gamma*x\n",
    "        return hidden\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(K={}, temp={})'.format(self.__class__.__name__, self.K,\n",
    "                                          self.temp)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(K={}, temp={})'.format(self.__class__.__name__, self.K,\n",
    "                                          self.temp)\n",
    "class GPRGNN(torch.nn.Module):\n",
    "    def __init__(self, dataset, args):\n",
    "        super(GPRGNN, self).__init__()\n",
    "        self.lin1 = Linear(dataset.num_features, args.hidden)\n",
    "        self.lin2 = Linear(args.hidden, dataset.num_classes)\n",
    "\n",
    "        self.prop1 = GPR_prop(args.K, args.alpha, args.Init)\n",
    "\n",
    "        self.Init = args.Init\n",
    "        self.dprate = args.dprate\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.prop1.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        if self.dprate == 0.0:\n",
    "            x = self.prop1(x, edge_index)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        else:\n",
    "            x = F.dropout(x, p=self.dprate, training=self.training)\n",
    "            x = self.prop1(x, edge_index)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "class BernNet(torch.nn.Module):\n",
    "    def __init__(self,dataset, args):\n",
    "        super(BernNet, self).__init__()\n",
    "        self.lin1 = Linear(dataset.num_features, args.hidden)\n",
    "        self.lin2 = Linear(args.hidden, dataset.num_classes)\n",
    "        self.m = torch.nn.BatchNorm1d(dataset.num_classes)\n",
    "        self.prop1 = Bern_prop(args.K)\n",
    "\n",
    "        self.dprate = args.dprate\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.prop1.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        #x= self.m(x)\n",
    "\n",
    "        if self.dprate == 0.0:\n",
    "            x = self.prop1(x, edge_index)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        else:\n",
    "            x = F.dropout(x, p=self.dprate, training=self.training)\n",
    "            x = self.prop1(x, edge_index)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GCN_Net(torch.nn.Module):\n",
    "    def __init__(self, dataset, args):\n",
    "        super(GCN_Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, args.hidden)\n",
    "        self.conv2 = GCNConv(args.hidden, dataset.num_classes)\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class ChebNet(torch.nn.Module):\n",
    "    def __init__(self, dataset, args):\n",
    "        super(ChebNet, self).__init__()\n",
    "        self.conv1 = ChebConv(dataset.num_features, 32, K=2)\n",
    "        self.conv2 = ChebConv(32, dataset.num_classes, K=2)\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class GAT_Net(torch.nn.Module):\n",
    "    def __init__(self, dataset, args):\n",
    "        super(GAT_Net, self).__init__()\n",
    "        self.conv1 = GATConv(\n",
    "            dataset.num_features,\n",
    "            args.hidden,\n",
    "            heads=args.heads,\n",
    "            dropout=args.dropout)\n",
    "        self.conv2 = GATConv(\n",
    "            args.hidden * args.heads,\n",
    "            dataset.num_classes,\n",
    "            heads=args.output_heads,\n",
    "            concat=False,\n",
    "            dropout=args.dropout)\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class APPNP_Net(torch.nn.Module):\n",
    "    def __init__(self, dataset, args):\n",
    "        super(APPNP_Net, self).__init__()\n",
    "        self.lin1 = Linear(dataset.num_features, args.hidden)\n",
    "        self.lin2 = Linear(args.hidden, dataset.num_classes)\n",
    "        self.prop1 = APPNP(args.K, args.alpha)\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = self.prop1(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dataset,args):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lin1 = Linear(dataset.num_features, args.hidden)\n",
    "        self.lin2 = Linear(args.hidden, dataset.num_classes)\n",
    "        self.dropout =args.dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf9f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
