{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349442a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import pickle\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import Coauthor\n",
    "from torch_geometric.datasets import Amazon\n",
    "from torch_geometric.nn import APPNP\n",
    "from torch_sparse import coalesce\n",
    "from torch_geometric.data import InMemoryDataset, download_url, Data\n",
    "from torch_geometric.utils.undirected import is_undirected, to_undirected\n",
    "from torch_geometric.io import read_npz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class dataset_heterophily(InMemoryDataset):\n",
    "    def __init__(self, root='data/', name=None,\n",
    "                 p2raw=None,\n",
    "                 train_percent=0.01,\n",
    "                 transform=None, pre_transform=None):\n",
    "        if name=='actor':\n",
    "            name='film'\n",
    "        existing_dataset = ['chameleon', 'film', 'squirrel']\n",
    "        if name not in existing_dataset:\n",
    "            raise ValueError(\n",
    "                f'name of hypergraph dataset must be one of: {existing_dataset}')\n",
    "        else:\n",
    "            self.name = name\n",
    "\n",
    "        self._train_percent = train_percent\n",
    "\n",
    "        if (p2raw is not None) and osp.isdir(p2raw):\n",
    "            self.p2raw = p2raw\n",
    "        elif p2raw is None:\n",
    "            self.p2raw = None\n",
    "        elif not osp.isdir(p2raw):\n",
    "            raise ValueError(\n",
    "                f'path to raw hypergraph dataset \"{p2raw}\" does not exist!')\n",
    "\n",
    "        if not osp.isdir(root):\n",
    "            os.makedirs(root)\n",
    "\n",
    "        self.root = root\n",
    "\n",
    "        super(dataset_heterophily, self).__init__(\n",
    "            root, transform, pre_transform)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        self.train_percent = self.data.train_percent.item()\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return osp.join(self.root, self.name, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return osp.join(self.root, self.name, 'processed')\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        file_names = [self.name]\n",
    "        return file_names\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        p2f = osp.join(self.raw_dir, self.name)\n",
    "        with open(p2f, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.name)\n",
    "\n",
    "\n",
    "class WebKB(InMemoryDataset):\n",
    "\n",
    "    url = ('https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/'\n",
    "           'master/new_data')\n",
    "\n",
    "    def __init__(self, root, name, transform=None, pre_transform=None):\n",
    "        self.name = name.lower()\n",
    "        assert self.name in ['cornell', 'texas', 'washington', 'wisconsin']\n",
    "\n",
    "        super(WebKB, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return osp.join(self.root, self.name, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return osp.join(self.root, self.name, 'processed')\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['out1_node_feature_label.txt', 'out1_graph_edges.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        for name in self.raw_file_names:\n",
    "            download_url(f'{self.url}/{self.name}/{name}', self.raw_dir)\n",
    "\n",
    "    def process(self):\n",
    "        with open(self.raw_paths[0], 'r') as f:\n",
    "            data = f.read().split('\\n')[1:-1]\n",
    "            x = [[float(v) for v in r.split('\\t')[1].split(',')] for r in data]\n",
    "            x = torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "            y = [int(r.split('\\t')[2]) for r in data]\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "        with open(self.raw_paths[1], 'r') as f:\n",
    "            data = f.read().split('\\n')[1:-1]\n",
    "            data = [[int(v) for v in r.split('\\t')] for r in data]\n",
    "            edge_index = torch.tensor(data, dtype=torch.long).t().contiguous()\n",
    "            edge_index = to_undirected(edge_index)\n",
    "            edge_index, _ = coalesce(edge_index, None, x.size(0), x.size(0))\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.name)\n",
    "\n",
    "\n",
    "def DataLoader(name):\n",
    "    \n",
    "    name = name.lower()\n",
    "    if name in ['cora', 'citeseer', 'pubmed']:\n",
    "        root_path = './'\n",
    "        path = osp.join(root_path, 'data', name)\n",
    "        dataset = Planetoid(path, name, transform=T.NormalizeFeatures())\n",
    "    elif name in ['computers', 'photo']:\n",
    "        root_path = './'\n",
    "        path = osp.join(root_path, 'data', name)\n",
    "        dataset = Amazon(path, name, T.NormalizeFeatures())\n",
    "    elif name in ['chameleon', 'actor', 'squirrel']:\n",
    "        dataset = dataset_heterophily(root='./data/', name=name, transform=T.NormalizeFeatures())\n",
    "\n",
    "    elif name in ['texas', 'cornell']:\n",
    "        dataset = WebKB(root='./data/',name=name, transform=T.NormalizeFeatures())\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'dataset {name} not supported in dataloader')\n",
    "\n",
    "    return dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
